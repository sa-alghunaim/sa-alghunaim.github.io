<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.1//EN"
  "http://www.w3.org/TR/xhtml11/DTD/xhtml11.dtd">
<html xmlns="http://www.w3.org/1999/xhtml" xml:lang="en">
<head>
<meta name="generator" content="jemdoc, see http://jemdoc.jaboc.net/" />
<meta http-equiv="Content-Type" content="text/html;charset=utf-8" />
<link rel="stylesheet" href="jemdoc.css" type="text/css" />
<title>Publications </title>
</head>
<body>
<table summary="Table for page layout." id="tlayout">
<tr valign="top">
<td id="layout-menu">
<div class="menu-category">S. A. Alghunaim</div>
<div class="menu-item"><a href="index.html">Home</a></div>
<div class="menu-item"><a href="teaching.html">Teaching</a></div>
<div class="menu-item"><a href="bio.html">Bio</a></div>
<div class="menu-category">Research</div>
<div class="menu-item"><a href="people.html">People</a></div>
<div class="menu-item"><a href="publications.html" class="current">Publications</a></div>
<div class="menu-item"><a href="./slides/slides.html">Slides</a></div>
<div class="menu-category">Classes</div>
<div class="menu-item"><a href="./courses/ee312/ee312.html">EE312</a></div>
<div class="menu-item"><a href="./courses/engr504/engr504.html">ENGR504</a></div>
<div class="menu-item"><a href="./courses/engr507/engr507.html">ENGR507</a></div>
</td>
<td id="layout-content">
<div id="toptitle">
<h1>Publications </h1>
</div>
<p><a href="https://scholar.google.com/citations?user=_FTElPsAAAAJ&amp;hl=en">Google scholar profile</a></p>
<h2>Preprints</h2>
<ul>
<li><p>H. Cai, <b>S. A. Alghunaim</b>, A. H. Sayed, &lsquo;&lsquo;<a href="https://arxiv.org/abs/2507.21901">Communication-efficient algorithms for distributed nonconvex minimax optimization problems</a>,&rsquo;&rsquo; arXiv:2507.21901, July, 2025. </p>
</li>
</ul>
<ul>
<li><p>H. Cai, <b>S. A. Alghunaim</b>, A. H. Sayed, &lsquo;&lsquo;<a href="https://arxiv.org/abs/2406.13041">Accelerated stochastic min-max optimization based on bias-corrected momentum</a>,&rsquo;&rsquo; arXiv:2406.1304, June, 2024. </p>
</li>
</ul>
<ul>
<li><p>L. Guo, <b>S. A. Alghunaim</b>, K. Yuan, L. Condat, J. Cao, &lsquo;&lsquo;<a href="https://arxiv.org/abs/2310.07983">Achieving linear speedup with ProxSkip in distributed stochastic optimization</a>,&rsquo;&rsquo; arXiv:2310.07983, Oct., 2023. </p>
</li>
</ul>
<h2>Journals and Conferences</h2>
<ul>
<li><p>[<b>J</b>] H. Cai, <b>S. A. Alghunaim</b>, A. H. Sayed, &lsquo;&lsquo;<a href="https://ieeexplore.ieee.org/document/10794742">Diffusion stochastic optimization for min-max problems</a>,&rsquo;&rsquo; <i>IEEE Trans. on Signal Processing</i>, vol. 73, pp. 259-274, 2025. <a href="https://arxiv.org/abs/2401.14585">[arXiv]</a></p>
</li>
</ul>
<ul>
<li><p>[<b>J</b>] <b>S. A. Alghunaim</b>, &lsquo;&lsquo;<a href="https://ieeexplore.ieee.org/document/10487872">Local exact-diffusion for decentralized optimization and learning</a>,&rsquo;&rsquo; <i>IEEE Trans. Automatic Control</i>, vol. 69, no. 11, pp. 7371-7386, Nov. 2024. <a href="https://arxiv.org/abs/2302.00620">[arXiv]</a></p>
</li>
</ul>
<ul>
<li><p>[<b>C</b>]  H. Cai, <b>S. A. Alghunaim</b>, A. H. Sayed, &lsquo;&lsquo;<a href="https://ieeexplore.ieee.org/document/10447140">Diffusion optimistic learning for min-max optimization</a>,&rsquo;&rsquo;  <i>Proc. IEEE ICASSP</i>, pp. 1-5, Seoul, South Korea, April 2024.</p>
</li>
</ul>
<ul>
<li><p>[<b>J</b>] <b>S. A. Alghunaim</b>, K. Yuan, &lsquo;&lsquo;<a href="https://www.sciencedirect.com/science/article/pii/S016516842300419X">An enhanced gradient-tracking bound for distributed online stochastic convex optimization</a>,&rsquo;&rsquo; <i>Signal Processing</i>, Volume 217, April 2024. <a href="https://arxiv.org/abs/2301.02855">[arXiv]</a></p>
</li>
</ul>
<ul>
<li><p>[<b>J</b>] K. Yuan, <b>S. A. Alghunaim</b>, X. Huang, &lsquo;&lsquo;<a href="https://jmlr.org/papers/v24/22-0283.html">Removing data heterogeneity influence enhances network topology dependence of decentralized SGD</a>,&rsquo;&rsquo; <i>Journal of Machine Learning Research</i> (JMLR), vol. 24, no. 280, pp. 1&ndash;53, 2023.   <a href="https://arxiv.org/abs/2105.08023">[arXiv]</a></p>
</li>
</ul>
<ul>
<li><p>[<b>C</b>] H. Yuan, <b>S. A. Alghunaim</b>, K. Yuan, &lsquo;&lsquo;<a href="https://ieeexplore.ieee.org/abstract/document/10384058">Achieving linear speedup with network-independent learning rates in decentralized stochastic optimization</a>,&rsquo;&rsquo; <i>Proc. IEEE CDC</i>, pp. 139-144, Marina Bay Sands, Singapore, December 2023.</p>
</li>
</ul>
<ul>
<li><p>[<b>C</b>] E. D. H. Nguyen, <b>S. A. Alghunaim</b>, K. Yuan, C. A. Uribe, &lsquo;&lsquo;<a href="https://ieeexplore.ieee.org/abstract/document/10383873">On the performance of gradient tracking with local updates</a>,&rsquo;&rsquo; <i>Proc. IEEE CDC</i>, pp. 4309-4313, Marina Bay Sands, Singapore, December 2023.  <a href="https://arxiv.org/abs/2210.04757">[arXiv]</a></p>
</li>
</ul>
<ul>
<li><p>[<b>J</b>] <b>S. A. Alghunaim</b>, K. Yuan, &lsquo;&lsquo;<a href="https://ieeexplore.ieee.org/document/9802673">A unified and refined convergence analysis for non-convex decentralized learning</a>,&rsquo;&rsquo; <i>IEEE Trans. on Signal Processing</i>, vol. 70, pp. 3264&ndash;3279, June 2022. 
<a href="https://arxiv.org/abs/2110.09993">[arXiv]</a></p>
</li>
</ul>
<ul>
<li><p>[<b>J</b>] <b>S. A. Alghunaim</b>, Q. Lyu, M. Yan, A. H. Sayed, &lsquo;&lsquo;<a href="https://ieeexplore.ieee.org/abstract/document/9547761">Dual consensus proximal algorithm for multi-agent sharing problems</a>,&rsquo;&rsquo; <i>IEEE Trans. on Signal Processing</i>, vol. 69, pp. 5568-5579, September 2021. </p>
</li>
</ul>
<ul>
<li><p>[<b>J</b>] <b>S. A. Alghunaim</b>, E. K. Ryu, K. Yuan, A. H. Sayed, &lsquo;&lsquo;<a href="https://ieeexplore.ieee.org/abstract/document/9141196">Decentralized proximal gradient algorithms with linear convergence rates</a>,&rsquo;&rsquo;  <i>IEEE Trans. Automatic Control</i>, vol. 66, no. 6, pp.  2787-2794, June 2021. 
<a href="https://arxiv.org/abs/1909.06479">[arXiv]</a></p>
</li>
</ul>
<ul>
<li><p>[<b>C</b>] <b>S. A. Alghunaim</b>, M. Yan, A. H. Sayed,  &lsquo;&lsquo;<a href="https://ieeexplore.ieee.org/abstract/document/9287370">A multi-agent primal-dual strategy for composite optimization over distributed features</a>,&rsquo;&rsquo;  in <i>Proc. EUSIPCO 2020</i>, pp. 2095-2099, Amsterdam, The Netherlands, January 2021. 
<a href="https://arxiv.org/abs/2006.08722">[arXiv]</a></p>
</li>
</ul>
<ul>
<li><p>[<b>J</b>] <b>S. A. Alghunaim</b>, K. Yuan, A. H. Sayed, &lsquo;&lsquo;<a href="https://ieeexplore.ieee.org/abstract/document/8935381">A proximal diffusion strategy for multi-agent optimization with sparse affine constraints</a>,&rsquo;&rsquo;  <i>IEEE Trans. Automatic Control</i>, vol. 65, no. 11, pp. 4554-4567, November 2020. 
<a href="https://arxiv.org/abs/1810.02124">[arXiv]</a></p>
</li>
</ul>
<ul>
<li><p>[<b>J</b>] K. Yuan, <b>S. A. Alghunaim</b>, B. Ying, A. H. Sayed. &lsquo;&lsquo;<a href="https://ieeexplore.ieee.org/abstract/document/9139399">On the influence of bias-correction on distributed stochastic optimization</a>,&rsquo;&rsquo; <i>IEEE Trans. on Signal Processing</i>, vol. 68,  4352-4367, July 2020.  <a href="https://arxiv.org/abs/1903.10956">[arXiv]</a></p>
</li>
</ul>
<ul>
<li><p>[<b>J</b>] <b>S. A. Alghunaim</b>, A. H. Sayed, &lsquo;&lsquo;<a href="https://www.sciencedirect.com/science/article/abs/pii/S0005109820302016">Linear convergence of primal-dual gradient methods and their performance in distributed optimization</a>,&rsquo;&rsquo; <i>Automatica</i>, Volume 117, July 2020. 
<a href="https://arxiv.org/abs/1904.01196">[arXiv]</a></p>
</li>
</ul>
<ul>
<li><p>[<b>J</b>] <b>S. A. Alghunaim</b>, A. H. Sayed, &lsquo;&lsquo;<a href="https://ieeexplore.ieee.org/abstract/document/8675446/">Distributed coupled multi-agent stochastic optimization</a>," <i>IEEE Trans. Automatic Control</i>, vol. 65, no. 1, pp. 175-190, January,  2020. 
<a href="https://arxiv.org/abs/1712.08817">[arXiv]</a></p>
</li>
</ul>
<ul>
<li><p>[<b>C</b>] <b>S. A. Alghunaim</b>, K. Yuan, A. H. Sayed, &lsquo;&lsquo;<a href="https://proceedings.neurips.cc/paper/2019/hash/e9fd7c2c6623306db59b6aef5c0d5cac-Abstract.html">A linearly convergent proximal gradient algorithm for decentralized  optimization</a>,&rsquo;&rsquo; in <i>Advances on Neural Information Processing Systems</i> (NeurIPS),  volume 32, Vancouver, Canada, December 2019. 
<a href="https://arxiv.org/abs/1905.07996">[arXiv]</a></p>
</li>
</ul>
<ul>
<li><p>[<b>C</b>] K. Yuan, <b>S. A. Alghunaim</b>, B. Ying, A. H. Sayed, &lsquo;&lsquo;<a href="https://ieeexplore.ieee.org/abstract/document/9029537">On the performance of exact diffusion over adaptive networks</a>,&rsquo;&rsquo; <i>Proc. IEEE CDC</i>,  pp. 4898-4903, Nice, France, December 2019. </p>
</li>
</ul>
<ul>
<li><p>[<b>C</b>] L. Cassano, <b>S. A. Alghunaim</b>, A. H. Sayed, &lsquo;&lsquo;<a href="https://ieeexplore.ieee.org/abstract/document/8683168">Team policy learning for multi-agent reinforcement learning</a>,&rsquo;&rsquo; <i>Proc. IEEE ICASSP</i>, pp. 3062-3066,  Brighton, UK, May 2019. </p>
</li>
</ul>
<ul>
<li><p>[<b>C</b>] <b>S. A. Alghunaim</b>, K. Yuan, A. H. Sayed, &lsquo;&lsquo;<a href="https://ieeexplore.ieee.org/abstract/document/8619343">Dual coupled diffusion for distributed optimization with affine constraints</a>,&rsquo;&rsquo; <i>Proc. IEEE CDC</i>, pp. 829-834,  Miami Beach, FL, USA, December 2018. </p>
</li>
</ul>
<ul>
<li><p>[<b>C</b>] <b>S. A. Alghunaim</b>, A. H. Sayed, &lsquo;&lsquo;<a href="https://ieeexplore.ieee.org/abstract/document/8461391">Distributed coupled learning over adaptive networks</a>,&rsquo;&rsquo; <i>Proc. IEEE ICASSP</i>, pp. 6353-6357, Calgary, Canada, April 2018. </p>
</li>
</ul>
<ul>
<li><p>[<b>C</b>] <b>S. A. Alghunaim</b>, K. Yuan, A. H. Sayed, &lsquo;&lsquo;<a href="https://ieeexplore.ieee.org/abstract/document/8262757">Decentralized exact coupled optimization</a>,&rsquo;&rsquo; <i>Proc. Allerton Conference on Communication, Control, and Computing</i>, pp. 338-345, Allerton, IL, October 2017.</p>
</li>
</ul>
<ul>
<li><p>[<b>C</b>] J. Y. Ishihara, <b>S. A. Alghunaim</b>,  &lsquo;&lsquo;<a href="https://ieeexplore.ieee.org/abstract/document/7963762">Diffusion LMS filter for distributed estimation of systems with stochastic state transition and observation matrices</a>,&rsquo;&rsquo; <i>Proc. American Control Conference (ACC)</i>, pp. 5199-5204, Seattle, USA, May, 2017.</p>
</li>
</ul>
<h2>Ph.D. Thesis </h2>
<p><b>S. A. Alghunaim</b>, <a href="https://escholarship.org/uc/item/1p19x685">On the Performance and Linear Convergence of Decentralized Primal-Dual Methods</a>, Doctoral dissertation, Electrical and Computer Engineering Department, UCLA, January 2020. </p>
</td>
</tr>
</table>
</body>
</html>
